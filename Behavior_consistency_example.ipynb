{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f021f70-77f2-477f-ae61-56aaa962e025",
   "metadata": {},
   "source": [
    "# Ask LLM a question. Here we go with LLAMA-7b, you can also try with other LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ca7ef4-01e3-4cde-b660-857e62142b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trustscore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/trustscore/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:13<00:00, 50.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 4096)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 4096)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 64)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 4096)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 64)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "llm=\"google/flan-t5-xxl\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(llm)\n",
    "model = T5ForConditionalGeneration.from_pretrained(llm)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138416ac-60e4-4317-bec7-566cbd5e3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''INSTRUCTION: Please give answers to the following questions about knowledge. \n",
    "\n",
    "Question: who has been ranked no. 1 in the latest football rankings announced by fifa?\n",
    "Answer: Argentina has been ranked no. 1 in the latest football rankings announced by fifa.\n",
    "\n",
    "Question: who sings i just want to use your love tonight?\n",
    "Answer: English rock band the Outfield sings i just want to use your love tonight.\n",
    "\n",
    "Question: where was the movie the glass castle filmed?\n",
    "Answer: The movie the glass castle was filmed in Welch, West Virginia.\n",
    "\n",
    "Question: who was the first lady nominated member of the rajya sabha?\n",
    "Answer: Mary Kom was the first lady nominated member of the rajya sabha.\n",
    "\n",
    "Question: what is the tigers name in life of pi?\n",
    "Answer: Richard Parker is the tigers name in life of pi.\n",
    "\n",
    "Question: {Q}\n",
    "Answer:'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e7a038-22a2-4261-908b-6e42ac8607f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"who is super bowl 2018 half time show?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5273db23-f165-4c33-9dcd-771758a94d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justin Timberlake\n"
     ]
    }
   ],
   "source": [
    "prompted_input=prompt.replace(\"{Q}\", question)\n",
    "model_inputs = tokenizer(prompted_input, return_tensors=\"pt\").to(device)\n",
    "greedy_output = model.generate(**model_inputs,max_length=512)\n",
    "pred=tokenizer.decode(greedy_output[0],skip_special_tokens=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf024164-e7c5-43cf-9df3-aabbd6a8ec6a",
   "metadata": {},
   "source": [
    "# Behavior Consistency\n",
    "\n",
    "1. generate distractor (In this project, we use a vocab-based method as illustrated in the papers. But definitly, you can always prompt chatgpt to do this)\n",
    "2. Make MCQs Test\n",
    "3. Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321d41ec-f18d-48b4-8d6b-bf4c87e7ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distractor_generator import distractor_generate\n",
    "max_check_limit = 10\n",
    "candidate_choices = distractor_generate(question, pred, limit=max_check_limit*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af03af3b-a499-4f68-baf2-ed18ae2b9cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mervyn King (darts player)',\n",
       " 'William Randolph Hearst',\n",
       " 'Arantxa Sánchez Vicario',\n",
       " 'Evonne Goolagong Cawley',\n",
       " 'David Gray (musician)',\n",
       " 'Yevgeny Kafelnikov',\n",
       " 'Sabrina Santamaria',\n",
       " 'Gabrielle (singer)',\n",
       " 'Kaitlyn Christian',\n",
       " 'Sarkodie (rapper)',\n",
       " 'Billie Jean King',\n",
       " 'David Williamson',\n",
       " 'Fernando Alonso',\n",
       " 'Gustavo Kuerten',\n",
       " 'David Coulthard',\n",
       " 'Joseph Pulitzer',\n",
       " 'Jonathan Palmer',\n",
       " 'Victor Gollancz',\n",
       " 'Jonas Björkman',\n",
       " 'Lleyton Hewitt',\n",
       " 'Lewis Hamilton',\n",
       " 'Jackie Stewart',\n",
       " 'Margaret Court',\n",
       " 'Martin Gardner',\n",
       " 'Gerhard Berger',\n",
       " 'Feist (singer)',\n",
       " 'Margaret Busby',\n",
       " 'Mohammad Hatta',\n",
       " 'Rajan–Nagendra',\n",
       " 'Richie Burnett',\n",
       " 'Jimmy Connors',\n",
       " 'Stefan Edberg',\n",
       " 'Stirling Moss',\n",
       " 'Dinara Safina',\n",
       " 'Thomas Muster',\n",
       " 'Mats Wilander',\n",
       " 'Jerry Douglas',\n",
       " 'Michael Tabor',\n",
       " \"Mark O'Connor\",\n",
       " 'Ronnie Baxter']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8cbfb4-f258-42ab-830b-9df9028e08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "mcq_num = 0\n",
    "choice_item=['A','B','C','D']\n",
    "used_choices=[]\n",
    "tests=[]\n",
    "answers=[]\n",
    "while mcq_num<max_check_limit:\n",
    "    choices = random.sample(candidate_choices, 3)\n",
    "    if sorted(choices) in used_choices:\n",
    "        continue\n",
    "    used_choices.append(sorted(choices))\n",
    "    choices = choices+[pred]\n",
    "    random.shuffle(choices)\n",
    "    random.shuffle(choices)\n",
    "    answers.append(choice_item[choices.index(pred)])\n",
    "    tests.append('%s\\nA) %s\\nB) %s\\nC) %s\\nD) %s\\nE) None of above.'%(question,choices[0],choices[1],choices[2],choices[3]))\n",
    "\n",
    "    mcq_num=mcq_num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e885eb80-9266-476c-9eb5-173f1beae102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is super bowl 2018 half time show?\n",
      "A) Mats Wilander\n",
      "B) Ronnie Baxter\n",
      "C) David Gray (musician)\n",
      "D) Justin Timberlake\n",
      "E) None of above.\n",
      "D\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Billie Jean King\n",
      "B) Victor Gollancz\n",
      "C) Justin Timberlake\n",
      "D) Rajan–Nagendra\n",
      "E) None of above.\n",
      "C\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Jonas Björkman\n",
      "B) Gabrielle (singer)\n",
      "C) Dinara Safina\n",
      "D) Justin Timberlake\n",
      "E) None of above.\n",
      "D\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Joseph Pulitzer\n",
      "B) Justin Timberlake\n",
      "C) Stefan Edberg\n",
      "D) Fernando Alonso\n",
      "E) None of above.\n",
      "B\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Justin Timberlake\n",
      "B) Stirling Moss\n",
      "C) Evonne Goolagong Cawley\n",
      "D) Sarkodie (rapper)\n",
      "E) None of above.\n",
      "A\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Evonne Goolagong Cawley\n",
      "B) Justin Timberlake\n",
      "C) Mark O'Connor\n",
      "D) Kaitlyn Christian\n",
      "E) None of above.\n",
      "B\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Kaitlyn Christian\n",
      "B) Lewis Hamilton\n",
      "C) Justin Timberlake\n",
      "D) Evonne Goolagong Cawley\n",
      "E) None of above.\n",
      "C\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Yevgeny Kafelnikov\n",
      "B) Richie Burnett\n",
      "C) Gerhard Berger\n",
      "D) Justin Timberlake\n",
      "E) None of above.\n",
      "D\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Michael Tabor\n",
      "B) Feist (singer)\n",
      "C) Justin Timberlake\n",
      "D) Mohammad Hatta\n",
      "E) None of above.\n",
      "C\n",
      "\n",
      "who is super bowl 2018 half time show?\n",
      "A) Jonathan Palmer\n",
      "B) Stirling Moss\n",
      "C) Jimmy Connors\n",
      "D) Justin Timberlake\n",
      "E) None of above.\n",
      "D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(tests):\n",
    "    print(t)\n",
    "    print(answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc28676-3631-420a-ad9d-f7632d83e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''INSTRUCTION: Please give answers to the following multi-choice questions about knowledge.\n",
    "\n",
    "Question: who has been ranked no. 1 in the latest football rankings announced by fifa?\n",
    "A) Germany has been ranked no. 1 in the latest football rankings announced by fifa.\n",
    "B) India has been ranked no. 1 in the latest football rankings announced by fifa.\n",
    "C) Canada has been ranked no. 1 in the latest football rankings announced by fifa.\n",
    "D) Austria has been ranked no. 1 in the latest football rankings announced by fifa.\n",
    "E) None of above.\n",
    "Answer: E\n",
    "\n",
    "Question: who sings i just want to use your love tonight?\n",
    "A) Latin rock band the Outfield sings i just want to use your love tonight.\n",
    "B) English Power pop band the Outfield sings i just want to use your love tonight.\n",
    "C) English rock band the Outfield sings i just want to use your love tonight.\n",
    "D) English melodic sensibility band the Outfield sings i just want to use your love tonight.\n",
    "E) None of above.\n",
    "Answer: C\n",
    "\n",
    "Question: where was the movie the glass castle filmed?\n",
    "A) The movie the glass castle was filmed in London.\n",
    "B) The movie the glass castle was filmed in Welch, West Virginia.\n",
    "C) The movie the glass castle was filmed in Philadelphia.\n",
    "D) The movie the glass castle was filmed in Budapest.\n",
    "E) None of above.\n",
    "Answer: B\n",
    "\n",
    "Question: who was the first lady nominated member of the rajya sabha?\n",
    "A) William Randolph Hearst was the first lady nominated member of the rajya sabha.\n",
    "B) Jesse Speight was the first lady nominated member of the rajya sabha.\n",
    "C) Thurlow Weed was the first lady nominated member of the rajya sabha.\n",
    "D) Mary Kom was the first lady nominated member of the rajya sabha.\n",
    "E) None of above.\n",
    "Answer: D\n",
    "\n",
    "Question: what is on a mcchicken sandwich from mcdonalds?\n",
    "A) A breaded chicken patty is on a mcchicken sandwich from mcdonalds.\n",
    "B) A Hot dog chicken patty is on a mcchicken sandwich from mcdonalds.\n",
    "C) A breaded Bacon is on a mcchicken sandwich from mcdonalds.\n",
    "D) A breaded Teriyaki chicken is on a mcchicken sandwich from mcdonalds.\n",
    "E) None of above.\n",
    "Answer: A\n",
    "\n",
    "Question: {Q}\n",
    "Answer:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ded927a-d4d1-428b-8f7b-4fc5a06435d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "behave_pred=[]\n",
    "for mc_q in tests:\n",
    "    prompted_input=prompt.replace(\"{Q}\", mc_q)\n",
    "    model_inputs = tokenizer(prompted_input, return_tensors=\"pt\",max_length=1024).to(device)\n",
    "    greedy_output = model.generate(**model_inputs,max_length=1024)\n",
    "    behave_pred.append(tokenizer.decode(greedy_output[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5dca6b5-23c5-4761-b14a-f8579d5f5327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'C', 'D', 'B', 'A', 'B', 'C', 'D', 'C', 'D']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behave_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346d3ce6-ee84-4deb-aec1-f5a62f999b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'C', 'D', 'B', 'A', 'B', 'C', 'D', 'C', 'D']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b365a6a-c137-4a85-9c30-c9ef57203e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if behave_pred != answers:\n",
    "    BC_score = 0\n",
    "else:\n",
    "    BC_score = 1\n",
    "\n",
    "print(BC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa234e88-1648-42a6-97a3-6e41e1db64f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustscore",
   "language": "python",
   "name": "trustscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
